[0m14:26:49.206442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000195AF1BB190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000195AF566C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000195AF432FD0>]}


============================== 14:26:49.216611 | 0a4207df-c884-4da5-9b65-888100dc5432 ==============================
[0m14:26:49.216611 [info ] [MainThread]: Running with dbt=1.11.2
[0m14:26:49.216611 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m14:26:49.246564 [info ] [MainThread]: dbt version: 1.11.2
[0m14:26:49.246564 [info ] [MainThread]: python version: 3.11.0
[0m14:26:49.246564 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m14:26:49.250264 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m14:26:49.478556 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m14:26:49.478556 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m14:26:49.478556 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m14:26:49.478556 [info ] [MainThread]: adapter type: postgres
[0m14:26:49.478556 [info ] [MainThread]: adapter version: 1.10.0
[0m14:26:49.600574 [info ] [MainThread]: Configuration:
[0m14:26:49.600574 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:26:49.600574 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:26:49.606724 [info ] [MainThread]: Required dependencies:
[0m14:26:49.606724 [debug] [MainThread]: Executing "git --help"
[0m14:26:49.651374 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:26:49.651374 [debug] [MainThread]: STDERR: "b''"
[0m14:26:49.656610 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:26:49.656610 [info ] [MainThread]: Connection:
[0m14:26:49.656610 [info ] [MainThread]:   host: localhost
[0m14:26:49.656610 [info ] [MainThread]:   port: 5432
[0m14:26:49.656610 [info ] [MainThread]:   user: your_username
[0m14:26:49.656610 [info ] [MainThread]:   database: medical_warehouse
[0m14:26:49.656610 [info ] [MainThread]:   schema: analytics
[0m14:26:49.656610 [info ] [MainThread]:   connect_timeout: 10
[0m14:26:49.656610 [info ] [MainThread]:   role: None
[0m14:26:49.656610 [info ] [MainThread]:   search_path: None
[0m14:26:49.656610 [info ] [MainThread]:   keepalives_idle: 0
[0m14:26:49.656610 [info ] [MainThread]:   sslmode: None
[0m14:26:49.664783 [info ] [MainThread]:   sslcert: None
[0m14:26:49.665401 [info ] [MainThread]:   sslkey: None
[0m14:26:49.665401 [info ] [MainThread]:   sslrootcert: None
[0m14:26:49.666407 [info ] [MainThread]:   application_name: dbt
[0m14:26:49.667415 [info ] [MainThread]:   retries: 1
[0m14:26:49.668417 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m14:26:49.946449 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m14:26:53.151524 [debug] [MainThread]: Using postgres connection "debug"
[0m14:26:53.156533 [debug] [MainThread]: On debug: select 1 as id
[0m14:26:53.156533 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:26:57.231512 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

[0m14:27:01.298272 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m14:27:01.298272 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m14:27:01.298272 [debug] [MainThread]: On debug: No close available on handle
[0m14:27:01.298272 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m14:27:01.302255 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:27:01.302255 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m14:27:01.306589 [debug] [MainThread]: Command `dbt debug` failed at 14:27:01.306589 after 12.16 seconds
[0m14:27:01.306589 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:27:01.308826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000195AF543C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000195A8B00D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000195A8B00E50>]}
[0m14:27:01.308826 [debug] [MainThread]: Flushing usage events
[0m14:27:02.563678 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:27:05.032382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021381ED6B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021381ED6350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021381EC4D10>]}


============================== 14:27:05.036626 | bd60c80f-44d4-4242-bee7-c90ae17c4327 ==============================
[0m14:27:05.036626 [info ] [MainThread]: Running with dbt=1.11.2
[0m14:27:05.036626 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt docs generate', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m14:27:05.301624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bd60c80f-44d4-4242-bee7-c90ae17c4327', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021381F65A50>]}
[0m14:27:05.356366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bd60c80f-44d4-4242-bee7-c90ae17c4327', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000213FE6D0F50>]}
[0m14:27:05.366648 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m14:27:05.658937 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m14:27:05.660946 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:27:05.660946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bd60c80f-44d4-4242-bee7-c90ae17c4327', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021383346C10>]}
[0m14:27:08.086700 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `relationships` defined on 'fct_messages' in
package 'medical_warehouse' (models\staging\schema.yml). Arguments to generic
tests should be nested under the `arguments` property.
[0m14:27:08.086700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'bd60c80f-44d4-4242-bee7-c90ae17c4327', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002138352C3D0>]}
[0m14:27:08.109316 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.medical_warehouse.stg_telegram_messages' (models\staging\stg_telegram_messages.sql) depends on a source named 'raw.telegram_messages' which was not found
[0m14:27:08.112069 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:27:08.113077 [debug] [MainThread]: Command `dbt docs generate` failed at 14:27:08.113077 after 3.16 seconds
[0m14:27:08.113077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021381ED4190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021381C79F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000213834BA190>]}
[0m14:27:08.113077 [debug] [MainThread]: Flushing usage events
[0m14:27:09.218852 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:27:11.611614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193C8376610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193C8292310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193C8291690>]}


============================== 14:27:11.614982 | 8ffb9fe4-3ba5-4a0b-99dc-e96011251eec ==============================
[0m14:27:11.614982 [info ] [MainThread]: Running with dbt=1.11.2
[0m14:27:11.616523 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt docs serve', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m14:27:11.816385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8ffb9fe4-3ba5-4a0b-99dc-e96011251eec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193C8367410>]}
[0m14:27:11.890503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8ffb9fe4-3ba5-4a0b-99dc-e96011251eec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193C4C009D0>]}
[0m14:27:11.926515 [error] [MainThread]: Encountered an error:
[WinError 2] The system cannot find the file specified: 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\target'
[0m14:27:11.928520 [error] [MainThread]: Traceback (most recent call last):
  File "E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Lib\site-packages\dbt\cli\requires.py", line 182, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Lib\site-packages\dbt\cli\requires.py", line 128, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Lib\site-packages\dbt\cli\requires.py", line 276, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Lib\site-packages\dbt\cli\requires.py", line 321, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Lib\site-packages\dbt\cli\requires.py", line 368, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Lib\site-packages\dbt\cli\main.py", line 307, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Lib\site-packages\dbt\task\docs\serve.py", line 15, in run
    os.chdir(self.config.project_target_path)
FileNotFoundError: [WinError 2] The system cannot find the file specified: 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\target'

[0m14:27:11.930637 [debug] [MainThread]: Command `dbt docs serve` failed at 14:27:11.930637 after 0.38 seconds
[0m14:27:11.930637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193C83D4710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193C83D5650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000193C8367D90>]}
[0m14:27:11.931637 [debug] [MainThread]: Flushing usage events
[0m14:27:13.066760 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:43:15.277434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B76C1E0E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B76B25A250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B76C259450>]}


============================== 14:43:15.285581 | 96c05dca-705e-429a-81ac-e7dabf1e5925 ==============================
[0m14:43:15.285581 [info ] [MainThread]: Running with dbt=1.11.2
[0m14:43:15.285581 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m14:43:15.313257 [info ] [MainThread]: dbt version: 1.11.2
[0m14:43:15.313257 [info ] [MainThread]: python version: 3.11.0
[0m14:43:15.313257 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m14:43:15.313257 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m14:43:15.372696 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m14:43:15.377400 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m14:43:15.378446 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m14:43:15.522832 [info ] [MainThread]: Configuration:
[0m14:43:15.527382 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:43:15.527876 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:43:15.527876 [info ] [MainThread]: Required dependencies:
[0m14:43:15.527876 [debug] [MainThread]: Executing "git --help"
[0m14:43:15.582636 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:43:15.582636 [debug] [MainThread]: STDERR: "b''"
[0m14:43:15.582636 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:43:15.587930 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:43:15.587930 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:43:15.587930 [info ] [MainThread]: Profile loading failed for the following reason:
Runtime Error
  Credentials in profile "medical_warehouse", target "dev" invalid: 12345678 is not of type 'string'


[0m14:43:15.587930 [debug] [MainThread]: Command `dbt debug` failed at 14:43:15.587930 after 0.39 seconds
[0m14:43:15.587930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B76BF999D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B76BF9A190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001B76C22FD50>]}
[0m14:43:15.587930 [debug] [MainThread]: Flushing usage events
[0m14:43:16.906402 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:46:20.823744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EBAF179C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EBAEFCD1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EBAF17AD90>]}


============================== 14:46:20.826315 | 1a9015bf-2edc-4241-964e-21818b8066c8 ==============================
[0m14:46:20.826315 [info ] [MainThread]: Running with dbt=1.11.2
[0m14:46:20.831988 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m14:46:20.895701 [info ] [MainThread]: dbt version: 1.11.2
[0m14:46:20.902914 [info ] [MainThread]: python version: 3.11.0
[0m14:46:20.908959 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m14:46:20.916862 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m14:46:21.153895 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m14:46:21.153895 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m14:46:21.155905 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m14:46:21.157936 [info ] [MainThread]: adapter type: postgres
[0m14:46:21.159946 [info ] [MainThread]: adapter version: 1.10.0
[0m14:46:21.371727 [info ] [MainThread]: Configuration:
[0m14:46:21.371727 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:46:21.371727 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:46:21.371727 [info ] [MainThread]: Required dependencies:
[0m14:46:21.371727 [debug] [MainThread]: Executing "git --help"
[0m14:46:21.436473 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:46:21.436473 [debug] [MainThread]: STDERR: "b''"
[0m14:46:21.441887 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:46:21.441887 [info ] [MainThread]: Connection:
[0m14:46:21.443897 [info ] [MainThread]:   host: localhost
[0m14:46:21.443897 [info ] [MainThread]:   port: 5432
[0m14:46:21.445915 [info ] [MainThread]:   user: postgres
[0m14:46:21.445915 [info ] [MainThread]:   database: medical_warehouse
[0m14:46:21.445915 [info ] [MainThread]:   schema: analytics
[0m14:46:21.445915 [info ] [MainThread]:   connect_timeout: 10
[0m14:46:21.449946 [info ] [MainThread]:   role: None
[0m14:46:21.450962 [info ] [MainThread]:   search_path: None
[0m14:46:21.451961 [info ] [MainThread]:   keepalives_idle: 0
[0m14:46:21.453049 [info ] [MainThread]:   sslmode: None
[0m14:46:21.453799 [info ] [MainThread]:   sslcert: None
[0m14:46:21.454239 [info ] [MainThread]:   sslkey: None
[0m14:46:21.456248 [info ] [MainThread]:   sslrootcert: None
[0m14:46:21.456248 [info ] [MainThread]:   application_name: dbt
[0m14:46:21.456248 [info ] [MainThread]:   retries: 1
[0m14:46:21.456248 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m14:46:21.875867 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m14:46:21.973995 [debug] [MainThread]: Using postgres connection "debug"
[0m14:46:21.973995 [debug] [MainThread]: On debug: select 1 as id
[0m14:46:21.976007 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:46:26.049707 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

[0m14:46:30.126686 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m14:46:30.128741 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m14:46:30.131770 [debug] [MainThread]: On debug: No close available on handle
[0m14:46:30.131770 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m14:46:30.137168 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:46:30.139206 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m14:46:30.146978 [debug] [MainThread]: Command `dbt debug` failed at 14:46:30.146978 after 9.41 seconds
[0m14:46:30.149351 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m14:46:30.150350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EBB02FDE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EBA8700D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002EBA8700E50>]}
[0m14:46:30.151857 [debug] [MainThread]: Flushing usage events
[0m14:46:31.252003 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:33:42.798688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EB57E4F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EB5838490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EB571D090>]}


============================== 20:33:42.807273 | 3f8fffac-e3fb-4b5b-b8f5-4318144d0d41 ==============================
[0m20:33:42.807273 [info ] [MainThread]: Running with dbt=1.11.2
[0m20:33:42.809245 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m20:33:42.848251 [info ] [MainThread]: dbt version: 1.11.2
[0m20:33:42.848251 [info ] [MainThread]: python version: 3.11.0
[0m20:33:42.848251 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m20:33:42.848251 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m20:33:43.188571 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m20:33:43.188571 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m20:33:43.188571 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m20:33:43.188571 [info ] [MainThread]: adapter type: postgres
[0m20:33:43.198194 [info ] [MainThread]: adapter version: 1.10.0
[0m20:33:43.555133 [info ] [MainThread]: Configuration:
[0m20:33:43.557133 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:33:43.559447 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:33:43.565758 [info ] [MainThread]: Required dependencies:
[0m20:33:43.567753 [debug] [MainThread]: Executing "git --help"
[0m20:33:43.743439 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:33:43.746175 [debug] [MainThread]: STDERR: "b''"
[0m20:33:43.747261 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:33:43.747261 [info ] [MainThread]: Connection:
[0m20:33:43.751601 [info ] [MainThread]:   host: localhost
[0m20:33:43.751601 [info ] [MainThread]:   port: 5432
[0m20:33:43.751601 [info ] [MainThread]:   user: postgres
[0m20:33:43.751601 [info ] [MainThread]:   database: medical_warehouse
[0m20:33:43.756563 [info ] [MainThread]:   schema: analytics
[0m20:33:43.759350 [info ] [MainThread]:   connect_timeout: 10
[0m20:33:43.760350 [info ] [MainThread]:   role: None
[0m20:33:43.761356 [info ] [MainThread]:   search_path: None
[0m20:33:43.764722 [info ] [MainThread]:   keepalives_idle: 0
[0m20:33:43.766726 [info ] [MainThread]:   sslmode: None
[0m20:33:43.769234 [info ] [MainThread]:   sslcert: None
[0m20:33:43.771254 [info ] [MainThread]:   sslkey: None
[0m20:33:43.773249 [info ] [MainThread]:   sslrootcert: None
[0m20:33:43.776147 [info ] [MainThread]:   application_name: dbt
[0m20:33:43.902002 [info ] [MainThread]:   retries: 1
[0m20:33:43.904973 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m20:33:44.646499 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:33:48.321353 [debug] [MainThread]: Using postgres connection "debug"
[0m20:33:48.323103 [debug] [MainThread]: On debug: select 1 as id
[0m20:33:48.323103 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:33:52.410941 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

[0m20:33:56.476713 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m20:33:56.476713 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m20:33:56.476713 [debug] [MainThread]: On debug: No close available on handle
[0m20:33:56.476713 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m20:33:56.476713 [info ] [MainThread]: [31m1 check failed:[0m
[0m20:33:56.476713 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m20:33:56.476713 [debug] [MainThread]: Command `dbt debug` failed at 20:33:56.476713 after 13.82 seconds
[0m20:33:56.476713 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:33:56.476713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EB57D3E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EB5595AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023EAED70D90>]}
[0m20:33:56.476713 [debug] [MainThread]: Flushing usage events
[0m20:33:57.984039 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:37:36.469211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA614C6B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA615183D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA61519410>]}


============================== 20:37:36.475701 | c19fcedd-0dca-4772-92c8-82feacc56a16 ==============================
[0m20:37:36.475701 [info ] [MainThread]: Running with dbt=1.11.2
[0m20:37:36.476651 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'use_colors': 'True', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m20:37:36.508583 [info ] [MainThread]: dbt version: 1.11.2
[0m20:37:36.509583 [info ] [MainThread]: python version: 3.11.0
[0m20:37:36.510582 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m20:37:36.511589 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m20:37:36.612484 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m20:37:36.613485 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m20:37:36.614486 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m20:37:36.616491 [info ] [MainThread]: adapter type: postgres
[0m20:37:36.617607 [info ] [MainThread]: adapter version: 1.10.0
[0m20:37:36.779432 [info ] [MainThread]: Configuration:
[0m20:37:36.779432 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:37:36.782650 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:37:36.782650 [info ] [MainThread]: Required dependencies:
[0m20:37:36.782650 [debug] [MainThread]: Executing "git --help"
[0m20:37:36.863182 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:37:36.864176 [debug] [MainThread]: STDERR: "b''"
[0m20:37:36.864176 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:37:36.866211 [info ] [MainThread]: Connection:
[0m20:37:36.867220 [info ] [MainThread]:   host: localhost
[0m20:37:36.868222 [info ] [MainThread]:   port: 5432
[0m20:37:36.869220 [info ] [MainThread]:   user: postgres
[0m20:37:36.870219 [info ] [MainThread]:   database: medical_warehouse
[0m20:37:36.871222 [info ] [MainThread]:   schema: analytics
[0m20:37:36.872225 [info ] [MainThread]:   connect_timeout: 10
[0m20:37:36.873223 [info ] [MainThread]:   role: None
[0m20:37:36.874218 [info ] [MainThread]:   search_path: None
[0m20:37:36.875727 [info ] [MainThread]:   keepalives_idle: 0
[0m20:37:36.876742 [info ] [MainThread]:   sslmode: None
[0m20:37:36.878018 [info ] [MainThread]:   sslcert: None
[0m20:37:36.879020 [info ] [MainThread]:   sslkey: None
[0m20:37:36.881024 [info ] [MainThread]:   sslrootcert: None
[0m20:37:36.882024 [info ] [MainThread]:   application_name: dbt
[0m20:37:36.883022 [info ] [MainThread]:   retries: 1
[0m20:37:36.885022 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m20:37:37.341792 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:37:37.442897 [debug] [MainThread]: Using postgres connection "debug"
[0m20:37:37.443902 [debug] [MainThread]: On debug: select 1 as id
[0m20:37:37.443902 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:37:41.495166 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
	Is the server running on that host and accepting TCP/IP connections?

[0m20:37:45.530438 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m20:37:45.530438 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m20:37:45.530438 [debug] [MainThread]: On debug: No close available on handle
[0m20:37:45.530438 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m20:37:45.530438 [info ] [MainThread]: [31m1 check failed:[0m
[0m20:37:45.530438 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (::1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)
  	Is the server running on that host and accepting TCP/IP connections?
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m20:37:45.537714 [debug] [MainThread]: Command `dbt debug` failed at 20:37:45.537714 after 9.16 seconds
[0m20:37:45.537714 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:37:45.541060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA614D5810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA614D5A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA604BC310>]}
[0m20:37:45.541060 [debug] [MainThread]: Flushing usage events
[0m20:37:46.947418 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:48:59.139223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5FE05F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5FE78D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5FE053D0>]}


============================== 20:48:59.146511 | 2b13fd0d-3c81-4e85-bdfb-c00a1e5bb838 ==============================
[0m20:48:59.146511 [info ] [MainThread]: Running with dbt=1.11.2
[0m20:48:59.146511 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m20:48:59.174963 [info ] [MainThread]: dbt version: 1.11.2
[0m20:48:59.174963 [info ] [MainThread]: python version: 3.11.0
[0m20:48:59.174963 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m20:48:59.177696 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m20:48:59.261082 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m20:48:59.261768 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m20:48:59.262774 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m20:48:59.264127 [info ] [MainThread]: adapter type: postgres
[0m20:48:59.264127 [info ] [MainThread]: adapter version: 1.10.0
[0m20:48:59.363904 [info ] [MainThread]: Configuration:
[0m20:48:59.363904 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m20:48:59.363904 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m20:48:59.363904 [info ] [MainThread]: Required dependencies:
[0m20:48:59.363904 [debug] [MainThread]: Executing "git --help"
[0m20:48:59.417734 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m20:48:59.417734 [debug] [MainThread]: STDERR: "b''"
[0m20:48:59.417734 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m20:48:59.417734 [info ] [MainThread]: Connection:
[0m20:48:59.417734 [info ] [MainThread]:   host: localhost
[0m20:48:59.417734 [info ] [MainThread]:   port: 5432
[0m20:48:59.417734 [info ] [MainThread]:   user: postgres
[0m20:48:59.417734 [info ] [MainThread]:   database: medical_warehouse
[0m20:48:59.417734 [info ] [MainThread]:   schema: analytics
[0m20:48:59.423965 [info ] [MainThread]:   connect_timeout: 10
[0m20:48:59.424570 [info ] [MainThread]:   role: None
[0m20:48:59.425578 [info ] [MainThread]:   search_path: None
[0m20:48:59.425578 [info ] [MainThread]:   keepalives_idle: 0
[0m20:48:59.426863 [info ] [MainThread]:   sslmode: None
[0m20:48:59.426863 [info ] [MainThread]:   sslcert: None
[0m20:48:59.427865 [info ] [MainThread]:   sslkey: None
[0m20:48:59.428866 [info ] [MainThread]:   sslrootcert: None
[0m20:48:59.428866 [info ] [MainThread]:   application_name: dbt
[0m20:48:59.429863 [info ] [MainThread]:   retries: 1
[0m20:48:59.430864 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m20:48:59.729018 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m20:48:59.807669 [debug] [MainThread]: Using postgres connection "debug"
[0m20:48:59.808997 [debug] [MainThread]: On debug: select 1 as id
[0m20:48:59.808997 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:48:59.890414 [debug] [MainThread]: SQL status: SELECT 1 in 0.081 seconds
[0m20:48:59.890897 [debug] [MainThread]: On debug: Close
[0m20:48:59.892146 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m20:48:59.892146 [info ] [MainThread]: [32mAll checks passed![0m
[0m20:48:59.894147 [debug] [MainThread]: Command `dbt debug` succeeded at 20:48:59.894147 after 0.82 seconds
[0m20:48:59.895146 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m20:48:59.895146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF5FDF3E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF59370E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF590C7190>]}
[0m20:48:59.896415 [debug] [MainThread]: Flushing usage events
[0m20:49:01.166284 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:50:03.475231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D895AC6BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D895B24E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D895AB1850>]}


============================== 20:50:03.480913 | 4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf ==============================
[0m20:50:03.480913 [info ] [MainThread]: Running with dbt=1.11.2
[0m20:50:03.481965 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'invocation_command': 'dbt run', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m20:50:03.707246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D896D29150>]}
[0m20:50:03.770547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8922F0990>]}
[0m20:50:03.772484 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m20:50:04.087132 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m20:50:04.088879 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m20:50:04.089455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D896D79F90>]}
[0m20:50:06.661637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D89707B810>]}
[0m20:50:06.758390 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m20:50:06.778999 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m20:50:06.813053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8974A1CD0>]}
[0m20:50:06.813053 [info ] [MainThread]: Found 4 models, 1 test, 1 source, 464 macros
[0m20:50:06.813053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8973BB510>]}
[0m20:50:06.816346 [info ] [MainThread]: 
[0m20:50:06.816346 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:50:06.816346 [info ] [MainThread]: 
[0m20:50:06.816346 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:50:06.823649 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse'
[0m20:50:06.915464 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m20:50:06.916461 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:50:06.917430 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:50:06.941701 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.027 seconds
[0m20:50:06.941701 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m20:50:06.948017 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m20:50:06.948017 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:50:06.950024 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:50:06.982914 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.036 seconds
[0m20:50:06.982914 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m20:50:06.988652 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_medical_warehouse, now create_medical_warehouse_analytics_staging)
[0m20:50:06.989286 [debug] [ThreadPool]: Creating schema "database: "medical_warehouse"
schema: "analytics_staging"
"
[0m20:50:06.993234 [debug] [ThreadPool]: Using postgres connection "create_medical_warehouse_analytics_staging"
[0m20:50:06.993234 [debug] [ThreadPool]: On create_medical_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "create_medical_warehouse_analytics_staging"} */
create schema if not exists "analytics_staging"
[0m20:50:06.993234 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:50:07.014707 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.021 seconds
[0m20:50:07.014707 [debug] [ThreadPool]: On create_medical_warehouse_analytics_staging: COMMIT
[0m20:50:07.018926 [debug] [ThreadPool]: Using postgres connection "create_medical_warehouse_analytics_staging"
[0m20:50:07.018926 [debug] [ThreadPool]: On create_medical_warehouse_analytics_staging: COMMIT
[0m20:50:07.020922 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m20:50:07.025026 [debug] [ThreadPool]: On create_medical_warehouse_analytics_staging: Close
[0m20:50:07.025026 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_medical_warehouse_analytics_staging, now create_medical_warehouse_analytics_marts)
[0m20:50:07.025026 [debug] [ThreadPool]: Creating schema "database: "medical_warehouse"
schema: "analytics_marts"
"
[0m20:50:07.025026 [debug] [ThreadPool]: Using postgres connection "create_medical_warehouse_analytics_marts"
[0m20:50:07.025026 [debug] [ThreadPool]: On create_medical_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "create_medical_warehouse_analytics_marts"} */
create schema if not exists "analytics_marts"
[0m20:50:07.031957 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:50:07.056098 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.033 seconds
[0m20:50:07.066945 [debug] [ThreadPool]: On create_medical_warehouse_analytics_marts: COMMIT
[0m20:50:07.066945 [debug] [ThreadPool]: Using postgres connection "create_medical_warehouse_analytics_marts"
[0m20:50:07.066945 [debug] [ThreadPool]: On create_medical_warehouse_analytics_marts: COMMIT
[0m20:50:07.068460 [debug] [ThreadPool]: SQL status: COMMIT in 0.003 seconds
[0m20:50:07.068460 [debug] [ThreadPool]: On create_medical_warehouse_analytics_marts: Close
[0m20:50:07.074271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse_analytics_staging'
[0m20:50:07.076810 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_staging"
[0m20:50:07.076810 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_staging"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m20:50:07.076810 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:50:07.114363 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.034 seconds
[0m20:50:07.114363 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: ROLLBACK
[0m20:50:07.118149 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: Close
[0m20:50:07.118149 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_medical_warehouse_analytics_staging, now list_medical_warehouse_analytics_marts)
[0m20:50:07.118149 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_marts"
[0m20:50:07.118149 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_marts"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m20:50:07.118149 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:50:07.145693 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.022 seconds
[0m20:50:07.147712 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: ROLLBACK
[0m20:50:07.148719 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: Close
[0m20:50:07.150838 [debug] [MainThread]: Using postgres connection "master"
[0m20:50:07.150838 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m20:50:07.150838 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:50:07.190347 [debug] [MainThread]: SQL status: SELECT 0 in 0.034 seconds
[0m20:50:07.193594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D896C6E990>]}
[0m20:50:07.193594 [debug] [MainThread]: On master: ROLLBACK
[0m20:50:07.193594 [debug] [MainThread]: On master: COMMIT
[0m20:50:07.193594 [debug] [MainThread]: Using postgres connection "master"
[0m20:50:07.193594 [debug] [MainThread]: On master: COMMIT
[0m20:50:07.193594 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m20:50:07.200784 [debug] [MainThread]: On master: Close
[0m20:50:07.209105 [debug] [Thread-1 (]: Began running node model.medical_warehouse.stg_telegram_messages
[0m20:50:07.209785 [info ] [Thread-1 (]: 1 of 2 START sql view model analytics_staging.stg_telegram_messages ............ [RUN]
[0m20:50:07.211300 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.medical_warehouse.stg_telegram_messages'
[0m20:50:07.211300 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.stg_telegram_messages
[0m20:50:07.221551 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.stg_telegram_messages"
[0m20:50:07.223632 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.stg_telegram_messages
[0m20:50:07.274025 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.stg_telegram_messages"
[0m20:50:07.277159 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m20:50:07.278165 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */

  create view "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_tmp"
    
    
  as (
    -- models/staging/stg_telegram_messages.sql

with source as (
    select
        message_id,
        channel_name,
        date::timestamp as message_date,
        message_text,
        length(message_text) as message_length,
        coalesce(view_count, 0) as view_count,
        coalesce(forward_count, 0) as forward_count,
        coalesce(has_image, false) as has_image,
        image_path
    from "medical_warehouse"."raw"."telegram_messages"
    where message_text is not null
)

select * from source
  );
[0m20:50:07.279164 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:50:07.314958 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.telegram_messages" does not exist
LINE 20:     from "medical_warehouse"."raw"."telegram_messages"
                  ^

[0m20:50:07.314958 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: ROLLBACK
[0m20:50:07.314958 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: Close
[0m20:50:07.479302 [debug] [Thread-1 (]: Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 20:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m20:50:07.483900 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a8b9ddf-b4cd-4cae-b99c-a71964bf68bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D89720C350>]}
[0m20:50:07.485420 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model analytics_staging.stg_telegram_messages ... [[31mERROR[0m in 0.27s]
[0m20:50:07.485420 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.stg_telegram_messages
[0m20:50:07.485420 [debug] [Thread-4 (]: Marking all children of 'model.medical_warehouse.stg_telegram_messages' to be skipped because of status 'error'.  Reason: Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 20:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql.
[0m20:50:07.488615 [debug] [Thread-1 (]: Began running node model.medical_warehouse.fct_messages
[0m20:50:07.489631 [info ] [Thread-1 (]: 2 of 2 SKIP relation analytics_marts.fct_messages .............................. [[33mSKIP[0m]
[0m20:50:07.489631 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.fct_messages
[0m20:50:07.491730 [debug] [MainThread]: On master: COMMIT
[0m20:50:07.491730 [debug] [MainThread]: Using postgres connection "master"
[0m20:50:07.491730 [debug] [MainThread]: On master: COMMIT
[0m20:50:07.491730 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:50:07.517311 [debug] [MainThread]: SQL status: COMMIT in 0.023 seconds
[0m20:50:07.518313 [debug] [MainThread]: On master: Close
[0m20:50:07.519974 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:50:07.521017 [debug] [MainThread]: Connection 'create_medical_warehouse_analytics_marts' was properly closed.
[0m20:50:07.522029 [debug] [MainThread]: Connection 'list_medical_warehouse_analytics_marts' was properly closed.
[0m20:50:07.523026 [debug] [MainThread]: Connection 'model.medical_warehouse.stg_telegram_messages' was properly closed.
[0m20:50:07.524026 [info ] [MainThread]: 
[0m20:50:07.525030 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.71 seconds (0.71s).
[0m20:50:07.527026 [debug] [MainThread]: Command end result
[0m20:50:07.562320 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m20:50:07.562320 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m20:50:07.573120 [debug] [MainThread]: Wrote artifact RunExecutionResult to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\run_results.json
[0m20:50:07.574069 [info ] [MainThread]: 
[0m20:50:07.574790 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:50:07.574790 [info ] [MainThread]: 
[0m20:50:07.574790 [error] [MainThread]: [31mFailure in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)[0m
[0m20:50:07.574790 [error] [MainThread]:   Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 20:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m20:50:07.574790 [info ] [MainThread]: 
[0m20:50:07.574790 [info ] [MainThread]:   compiled code at target\compiled\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m20:50:07.574790 [info ] [MainThread]: 
[0m20:50:07.574790 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m20:50:07.582832 [debug] [MainThread]: Command `dbt run` failed at 20:50:07.582832 after 4.16 seconds
[0m20:50:07.582832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D895B01A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D88ED96610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D897396010>]}
[0m20:50:07.582832 [debug] [MainThread]: Flushing usage events
[0m20:50:10.006891 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:58:27.675193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5448E6950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5448E6490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5448E6AD0>]}


============================== 20:58:27.689004 | a862fffc-4aad-4354-88c6-0ced05582526 ==============================
[0m20:58:27.689004 [info ] [MainThread]: Running with dbt=1.11.2
[0m20:58:27.689004 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m20:58:27.893960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a862fffc-4aad-4354-88c6-0ced05582526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5459FCF90>]}
[0m20:58:27.972355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a862fffc-4aad-4354-88c6-0ced05582526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5411107D0>]}
[0m20:58:27.974392 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m20:58:28.421493 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m20:58:28.606399 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:58:28.607667 [debug] [MainThread]: Partial parsing: updated file: medical_warehouse://models\staging\stg_telegram_messages.sql
[0m20:58:28.910295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a862fffc-4aad-4354-88c6-0ced05582526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D545A88910>]}
[0m20:58:29.001863 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m20:58:29.005448 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m20:58:29.080276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a862fffc-4aad-4354-88c6-0ced05582526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D545DB9250>]}
[0m20:58:29.081473 [info ] [MainThread]: Found 4 models, 1 test, 1 source, 464 macros
[0m20:58:29.082438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a862fffc-4aad-4354-88c6-0ced05582526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D546016950>]}
[0m20:58:29.084055 [info ] [MainThread]: 
[0m20:58:29.085031 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:58:29.085031 [info ] [MainThread]: 
[0m20:58:29.086359 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:58:29.091067 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse'
[0m20:58:29.170553 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m20:58:29.170553 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:58:29.170553 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:58:29.221473 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.049 seconds
[0m20:58:29.221473 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m20:58:29.221473 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m20:58:29.221473 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:58:29.221473 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:29.242512 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.018 seconds
[0m20:58:29.242512 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m20:58:29.251346 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse_analytics_marts'
[0m20:58:29.253766 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_marts"
[0m20:58:29.253766 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_marts"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m20:58:29.253766 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:58:29.286064 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.030 seconds
[0m20:58:29.286064 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: ROLLBACK
[0m20:58:29.286064 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: Close
[0m20:58:29.286064 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_medical_warehouse_analytics_marts, now list_medical_warehouse_analytics_staging)
[0m20:58:29.294275 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_staging"
[0m20:58:29.294275 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_staging"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m20:58:29.294275 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:29.333308 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.037 seconds
[0m20:58:29.336171 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: ROLLBACK
[0m20:58:29.336171 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: Close
[0m20:58:29.343792 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:29.343792 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m20:58:29.343792 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:58:29.386050 [debug] [MainThread]: SQL status: SELECT 0 in 0.041 seconds
[0m20:58:29.386050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a862fffc-4aad-4354-88c6-0ced05582526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D546407CD0>]}
[0m20:58:29.386050 [debug] [MainThread]: On master: ROLLBACK
[0m20:58:29.388877 [debug] [MainThread]: On master: COMMIT
[0m20:58:29.388877 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:29.388877 [debug] [MainThread]: On master: COMMIT
[0m20:58:29.388877 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m20:58:29.388877 [debug] [MainThread]: On master: Close
[0m20:58:29.399190 [debug] [Thread-1 (]: Began running node model.medical_warehouse.stg_telegram_messages
[0m20:58:29.399190 [info ] [Thread-1 (]: 1 of 2 START sql view model analytics_staging.stg_telegram_messages ............ [RUN]
[0m20:58:29.399190 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.medical_warehouse.stg_telegram_messages'
[0m20:58:29.401263 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.stg_telegram_messages
[0m20:58:29.409515 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.stg_telegram_messages"
[0m20:58:29.409515 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.stg_telegram_messages
[0m20:58:29.443229 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.stg_telegram_messages"
[0m20:58:29.450750 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m20:58:29.450750 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */

  create view "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_tmp"
    
    
  as (
    with source as (

    select *
    from "medical_warehouse"."raw"."telegram_messages"

),

cleaned as (

    select
        message_id,
        channel_name,
        message_text,
        message_date::timestamp as message_date,
        views::int as view_count,
        forwards::int as forward_count,
        has_media,
        length(message_text) as message_length
    from source
    where message_text is not null

)

select * from cleaned
  );
[0m20:58:29.450750 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:58:29.486333 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.telegram_messages" does not exist
LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                  ^

[0m20:58:29.486333 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: ROLLBACK
[0m20:58:29.486333 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: Close
[0m20:58:29.495377 [debug] [Thread-1 (]: Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m20:58:29.495377 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a862fffc-4aad-4354-88c6-0ced05582526', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D546423D50>]}
[0m20:58:29.495377 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model analytics_staging.stg_telegram_messages ... [[31mERROR[0m in 0.10s]
[0m20:58:29.495377 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.stg_telegram_messages
[0m20:58:29.495377 [debug] [Thread-4 (]: Marking all children of 'model.medical_warehouse.stg_telegram_messages' to be skipped because of status 'error'.  Reason: Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql.
[0m20:58:29.502328 [debug] [Thread-1 (]: Began running node model.medical_warehouse.fct_messages
[0m20:58:29.502710 [info ] [Thread-1 (]: 2 of 2 SKIP relation analytics_marts.fct_messages .............................. [[33mSKIP[0m]
[0m20:58:29.502710 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.fct_messages
[0m20:58:29.502710 [debug] [MainThread]: On master: COMMIT
[0m20:58:29.502710 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:29.502710 [debug] [MainThread]: On master: COMMIT
[0m20:58:29.502710 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:58:29.525880 [debug] [MainThread]: SQL status: COMMIT in 0.025 seconds
[0m20:58:29.525880 [debug] [MainThread]: On master: Close
[0m20:58:29.525880 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:58:29.525880 [debug] [MainThread]: Connection 'list_medical_warehouse' was properly closed.
[0m20:58:29.534193 [debug] [MainThread]: Connection 'list_medical_warehouse_analytics_staging' was properly closed.
[0m20:58:29.534193 [debug] [MainThread]: Connection 'model.medical_warehouse.stg_telegram_messages' was properly closed.
[0m20:58:29.535587 [info ] [MainThread]: 
[0m20:58:29.536597 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m20:58:29.538597 [debug] [MainThread]: Command end result
[0m20:58:29.565402 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m20:58:29.566421 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m20:58:29.577594 [debug] [MainThread]: Wrote artifact RunExecutionResult to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\run_results.json
[0m20:58:29.577594 [info ] [MainThread]: 
[0m20:58:29.578593 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:58:29.579622 [info ] [MainThread]: 
[0m20:58:29.579622 [error] [MainThread]: [31mFailure in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)[0m
[0m20:58:29.580625 [error] [MainThread]:   Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m20:58:29.580625 [info ] [MainThread]: 
[0m20:58:29.580625 [info ] [MainThread]:   compiled code at target\compiled\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m20:58:29.580625 [info ] [MainThread]: 
[0m20:58:29.580625 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m20:58:29.580625 [debug] [MainThread]: Command `dbt run` failed at 20:58:29.580625 after 1.96 seconds
[0m20:58:29.585569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D54496CAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D543A1CC10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D5410E5BD0>]}
[0m20:58:29.586083 [debug] [MainThread]: Flushing usage events
[0m20:58:31.011250 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:00:18.515073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C8A765C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C8A7B8950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C8A41B290>]}


============================== 21:00:18.520063 | aadb5508-82cc-4887-84e5-706ecea086d0 ==============================
[0m21:00:18.520063 [info ] [MainThread]: Running with dbt=1.11.2
[0m21:00:18.520063 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt debug', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m21:00:18.543146 [info ] [MainThread]: dbt version: 1.11.2
[0m21:00:18.543842 [info ] [MainThread]: python version: 3.11.0
[0m21:00:18.543842 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m21:00:18.543842 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m21:00:18.602290 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m21:00:18.602290 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m21:00:18.602290 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m21:00:18.602290 [info ] [MainThread]: adapter type: postgres
[0m21:00:18.609161 [info ] [MainThread]: adapter version: 1.10.0
[0m21:00:18.715248 [info ] [MainThread]: Configuration:
[0m21:00:18.716455 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m21:00:18.716455 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:00:18.716455 [info ] [MainThread]: Required dependencies:
[0m21:00:18.716455 [debug] [MainThread]: Executing "git --help"
[0m21:00:18.760807 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:00:18.760807 [debug] [MainThread]: STDERR: "b''"
[0m21:00:18.760807 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:00:18.760807 [info ] [MainThread]: Connection:
[0m21:00:18.760807 [info ] [MainThread]:   host: localhost
[0m21:00:18.760807 [info ] [MainThread]:   port: 5432
[0m21:00:18.760807 [info ] [MainThread]:   user: postgres
[0m21:00:18.760807 [info ] [MainThread]:   database: medical_warehouse
[0m21:00:18.768131 [info ] [MainThread]:   schema: analytics
[0m21:00:18.768131 [info ] [MainThread]:   connect_timeout: 10
[0m21:00:18.768131 [info ] [MainThread]:   role: None
[0m21:00:18.768131 [info ] [MainThread]:   search_path: None
[0m21:00:18.768131 [info ] [MainThread]:   keepalives_idle: 0
[0m21:00:18.768131 [info ] [MainThread]:   sslmode: None
[0m21:00:18.768131 [info ] [MainThread]:   sslcert: None
[0m21:00:18.768131 [info ] [MainThread]:   sslkey: None
[0m21:00:18.768131 [info ] [MainThread]:   sslrootcert: None
[0m21:00:18.768131 [info ] [MainThread]:   application_name: dbt
[0m21:00:18.768131 [info ] [MainThread]:   retries: 1
[0m21:00:18.768131 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m21:00:19.046701 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m21:00:19.116267 [debug] [MainThread]: Using postgres connection "debug"
[0m21:00:19.116267 [debug] [MainThread]: On debug: select 1 as id
[0m21:00:19.116267 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:00:19.139893 [debug] [MainThread]: SQL status: SELECT 1 in 0.023 seconds
[0m21:00:19.139893 [debug] [MainThread]: On debug: Close
[0m21:00:19.139893 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m21:00:19.139893 [info ] [MainThread]: [32mAll checks passed![0m
[0m21:00:19.139893 [debug] [MainThread]: Command `dbt debug` succeeded at 21:00:19.139893 after 0.69 seconds
[0m21:00:19.139893 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m21:00:19.139893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C8A7D8650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C8A7DB150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021C8BB55B90>]}
[0m21:00:19.139893 [debug] [MainThread]: Flushing usage events
[0m21:00:20.508032 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:00:25.133795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023D6A5410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023D6F1F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023D6A7E50>]}


============================== 21:00:25.138427 | 54af991f-4d09-457a-b68c-c684f5f417d6 ==============================
[0m21:00:25.138427 [info ] [MainThread]: Running with dbt=1.11.2
[0m21:00:25.138427 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'invocation_command': 'dbt run', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m21:00:25.336449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '54af991f-4d09-457a-b68c-c684f5f417d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023E8D71D0>]}
[0m21:00:25.400062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '54af991f-4d09-457a-b68c-c684f5f417d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020239ED0A10>]}
[0m21:00:25.400062 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m21:00:25.712661 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m21:00:25.859619 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:00:25.859619 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m21:00:25.859619 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:00:25.910248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '54af991f-4d09-457a-b68c-c684f5f417d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023E90B790>]}
[0m21:00:26.004016 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:00:26.006021 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:00:26.032633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '54af991f-4d09-457a-b68c-c684f5f417d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023EB976D0>]}
[0m21:00:26.032633 [info ] [MainThread]: Found 4 models, 1 test, 1 source, 464 macros
[0m21:00:26.032633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54af991f-4d09-457a-b68c-c684f5f417d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023D712E10>]}
[0m21:00:26.032633 [info ] [MainThread]: 
[0m21:00:26.032633 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:00:26.032633 [info ] [MainThread]: 
[0m21:00:26.032633 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:00:26.042965 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse'
[0m21:00:26.128134 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m21:00:26.129129 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:00:26.129129 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:00:26.152290 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.023 seconds
[0m21:00:26.153290 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m21:00:26.157085 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m21:00:26.157085 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:00:26.158147 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:00:26.187209 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.029 seconds
[0m21:00:26.187209 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m21:00:26.190845 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse_analytics_staging'
[0m21:00:26.197564 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_staging"
[0m21:00:26.197564 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_staging"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m21:00:26.197564 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:00:26.229373 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.038 seconds
[0m21:00:26.239314 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: ROLLBACK
[0m21:00:26.239865 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: Close
[0m21:00:26.239865 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_medical_warehouse_analytics_staging, now list_medical_warehouse_analytics_marts)
[0m21:00:26.250216 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_marts"
[0m21:00:26.250216 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_marts"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m21:00:26.250216 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:00:26.260422 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.018 seconds
[0m21:00:26.270757 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: ROLLBACK
[0m21:00:26.271430 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: Close
[0m21:00:26.312352 [debug] [MainThread]: Using postgres connection "master"
[0m21:00:26.319052 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m21:00:26.319680 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:00:26.349608 [debug] [MainThread]: SQL status: SELECT 0 in 0.031 seconds
[0m21:00:26.351955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54af991f-4d09-457a-b68c-c684f5f417d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023C11A750>]}
[0m21:00:26.351955 [debug] [MainThread]: On master: ROLLBACK
[0m21:00:26.353970 [debug] [MainThread]: On master: COMMIT
[0m21:00:26.353970 [debug] [MainThread]: Using postgres connection "master"
[0m21:00:26.353970 [debug] [MainThread]: On master: COMMIT
[0m21:00:26.353970 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m21:00:26.353970 [debug] [MainThread]: On master: Close
[0m21:00:26.353970 [debug] [Thread-1 (]: Began running node model.medical_warehouse.stg_telegram_messages
[0m21:00:26.353970 [info ] [Thread-1 (]: 1 of 2 START sql view model analytics_staging.stg_telegram_messages ............ [RUN]
[0m21:00:26.364325 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.medical_warehouse.stg_telegram_messages'
[0m21:00:26.364325 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.stg_telegram_messages
[0m21:00:26.368002 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.stg_telegram_messages"
[0m21:00:26.368002 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.stg_telegram_messages
[0m21:00:26.407895 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.stg_telegram_messages"
[0m21:00:26.407895 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:00:26.407895 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */

  create view "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_tmp"
    
    
  as (
    with source as (

    select *
    from "medical_warehouse"."raw"."telegram_messages"

),

cleaned as (

    select
        message_id,
        channel_name,
        message_text,
        message_date::timestamp as message_date,
        views::int as view_count,
        forwards::int as forward_count,
        has_media,
        length(message_text) as message_length
    from source
    where message_text is not null

)

select * from cleaned
  );
[0m21:00:26.407895 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:00:26.435230 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.telegram_messages" does not exist
LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                  ^

[0m21:00:26.435230 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: ROLLBACK
[0m21:00:26.437798 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: Close
[0m21:00:26.442921 [debug] [Thread-1 (]: Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m21:00:26.445917 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54af991f-4d09-457a-b68c-c684f5f417d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023D6F2CD0>]}
[0m21:00:26.445917 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model analytics_staging.stg_telegram_messages ... [[31mERROR[0m in 0.08s]
[0m21:00:26.446917 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.stg_telegram_messages
[0m21:00:26.448189 [debug] [Thread-4 (]: Marking all children of 'model.medical_warehouse.stg_telegram_messages' to be skipped because of status 'error'.  Reason: Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql.
[0m21:00:26.450154 [debug] [Thread-1 (]: Began running node model.medical_warehouse.fct_messages
[0m21:00:26.450154 [info ] [Thread-1 (]: 2 of 2 SKIP relation analytics_marts.fct_messages .............................. [[33mSKIP[0m]
[0m21:00:26.451175 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.fct_messages
[0m21:00:26.452184 [debug] [MainThread]: On master: COMMIT
[0m21:00:26.453216 [debug] [MainThread]: Using postgres connection "master"
[0m21:00:26.453216 [debug] [MainThread]: On master: COMMIT
[0m21:00:26.454215 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:00:26.485890 [debug] [MainThread]: SQL status: COMMIT in 0.032 seconds
[0m21:00:26.485890 [debug] [MainThread]: On master: Close
[0m21:00:26.485890 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:00:26.488710 [debug] [MainThread]: Connection 'list_medical_warehouse' was properly closed.
[0m21:00:26.488710 [debug] [MainThread]: Connection 'list_medical_warehouse_analytics_marts' was properly closed.
[0m21:00:26.488710 [debug] [MainThread]: Connection 'model.medical_warehouse.stg_telegram_messages' was properly closed.
[0m21:00:26.488710 [info ] [MainThread]: 
[0m21:00:26.491013 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m21:00:26.491730 [debug] [MainThread]: Command end result
[0m21:00:26.516573 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:00:26.519766 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:00:26.524403 [debug] [MainThread]: Wrote artifact RunExecutionResult to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\run_results.json
[0m21:00:26.524403 [info ] [MainThread]: 
[0m21:00:26.524403 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:00:26.530292 [info ] [MainThread]: 
[0m21:00:26.530292 [error] [MainThread]: [31mFailure in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)[0m
[0m21:00:26.530292 [error] [MainThread]:   Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m21:00:26.530292 [info ] [MainThread]: 
[0m21:00:26.530292 [info ] [MainThread]:   compiled code at target\compiled\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m21:00:26.534162 [info ] [MainThread]: 
[0m21:00:26.534162 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m21:00:26.536677 [debug] [MainThread]: Command `dbt run` failed at 21:00:26.536677 after 1.46 seconds
[0m21:00:26.536677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023F0BFA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020236976590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002023F0C75D0>]}
[0m21:00:26.536677 [debug] [MainThread]: Flushing usage events
[0m21:00:27.774114 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:02:31.439011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014539864510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001453895C990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001453895CA50>]}


============================== 21:02:31.443069 | 630db6f9-649c-4840-9dce-1d6889a60170 ==============================
[0m21:02:31.443069 [info ] [MainThread]: Running with dbt=1.11.2
[0m21:02:31.443069 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'introspect': 'True', 'log_cache_events': 'False', 'empty': 'None', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt debug', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m21:02:31.463741 [info ] [MainThread]: dbt version: 1.11.2
[0m21:02:31.463741 [info ] [MainThread]: python version: 3.11.0
[0m21:02:31.463741 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m21:02:31.474019 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m21:02:31.528670 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m21:02:31.528670 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m21:02:31.528670 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m21:02:31.528670 [info ] [MainThread]: adapter type: postgres
[0m21:02:31.528670 [info ] [MainThread]: adapter version: 1.10.0
[0m21:02:31.644134 [info ] [MainThread]: Configuration:
[0m21:02:31.650866 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m21:02:31.650866 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:02:31.650866 [info ] [MainThread]: Required dependencies:
[0m21:02:31.650866 [debug] [MainThread]: Executing "git --help"
[0m21:02:31.694630 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:02:31.697666 [debug] [MainThread]: STDERR: "b''"
[0m21:02:31.697666 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:02:31.697666 [info ] [MainThread]: Connection:
[0m21:02:31.697666 [info ] [MainThread]:   host: localhost
[0m21:02:31.697666 [info ] [MainThread]:   port: 5432
[0m21:02:31.697666 [info ] [MainThread]:   user: postgres
[0m21:02:31.701995 [info ] [MainThread]:   database: medical_warehouse
[0m21:02:31.701995 [info ] [MainThread]:   schema: analytics
[0m21:02:31.701995 [info ] [MainThread]:   connect_timeout: 10
[0m21:02:31.701995 [info ] [MainThread]:   role: None
[0m21:02:31.701995 [info ] [MainThread]:   search_path: None
[0m21:02:31.701995 [info ] [MainThread]:   keepalives_idle: 0
[0m21:02:31.701995 [info ] [MainThread]:   sslmode: None
[0m21:02:31.701995 [info ] [MainThread]:   sslcert: None
[0m21:02:31.701995 [info ] [MainThread]:   sslkey: None
[0m21:02:31.701995 [info ] [MainThread]:   sslrootcert: None
[0m21:02:31.701995 [info ] [MainThread]:   application_name: dbt
[0m21:02:31.701995 [info ] [MainThread]:   retries: 1
[0m21:02:31.710191 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m21:02:31.995308 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m21:02:32.060178 [debug] [MainThread]: Using postgres connection "debug"
[0m21:02:32.061259 [debug] [MainThread]: On debug: select 1 as id
[0m21:02:32.061804 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:02:32.136974 [debug] [MainThread]: SQL status: SELECT 1 in 0.080 seconds
[0m21:02:32.142238 [debug] [MainThread]: On debug: Close
[0m21:02:32.143412 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m21:02:32.144923 [info ] [MainThread]: [32mAll checks passed![0m
[0m21:02:32.146935 [debug] [MainThread]: Command `dbt debug` succeeded at 21:02:32.146935 after 0.77 seconds
[0m21:02:32.147936 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m21:02:32.149931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000145398889D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001453988B150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001453AC20BD0>]}
[0m21:02:32.150931 [debug] [MainThread]: Flushing usage events
[0m21:02:33.398983 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:02:39.022793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011372D37A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011372D80C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011372DA1690>]}


============================== 21:02:39.022793 | 05a3dfef-a642-4889-b804-4a14f966960a ==============================
[0m21:02:39.022793 [info ] [MainThread]: Running with dbt=1.11.2
[0m21:02:39.022793 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m21:02:39.225550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '05a3dfef-a642-4889-b804-4a14f966960a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011372DB94D0>]}
[0m21:02:39.291796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '05a3dfef-a642-4889-b804-4a14f966960a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001136F5A0210>]}
[0m21:02:39.293107 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m21:02:39.571004 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m21:02:39.705261 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:02:39.705261 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m21:02:39.705261 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:02:39.756647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '05a3dfef-a642-4889-b804-4a14f966960a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011373F9C690>]}
[0m21:02:39.854943 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:02:39.857942 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:02:39.885596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '05a3dfef-a642-4889-b804-4a14f966960a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000113742E4110>]}
[0m21:02:39.886571 [info ] [MainThread]: Found 4 models, 1 test, 1 source, 464 macros
[0m21:02:39.887573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05a3dfef-a642-4889-b804-4a14f966960a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011374236490>]}
[0m21:02:39.889595 [info ] [MainThread]: 
[0m21:02:39.889595 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:02:39.890569 [info ] [MainThread]: 
[0m21:02:39.891610 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:02:39.891610 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse'
[0m21:02:39.974429 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m21:02:39.975134 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:02:39.976238 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:02:40.000642 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.025 seconds
[0m21:02:40.000642 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m21:02:40.004404 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m21:02:40.004404 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:02:40.004404 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:02:40.035656 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.031 seconds
[0m21:02:40.040666 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m21:02:40.040666 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse_analytics_staging'
[0m21:02:40.045980 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_staging"
[0m21:02:40.045980 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_staging"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m21:02:40.045980 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:02:40.087668 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.038 seconds
[0m21:02:40.087668 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: ROLLBACK
[0m21:02:40.087668 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: Close
[0m21:02:40.087668 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_medical_warehouse_analytics_staging, now list_medical_warehouse_analytics_marts)
[0m21:02:40.087668 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_marts"
[0m21:02:40.087668 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_marts"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m21:02:40.087668 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:02:40.134769 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.037 seconds
[0m21:02:40.135806 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: ROLLBACK
[0m21:02:40.136787 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: Close
[0m21:02:40.180681 [debug] [MainThread]: Using postgres connection "master"
[0m21:02:40.180681 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m21:02:40.180681 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:02:40.220575 [debug] [MainThread]: SQL status: SELECT 0 in 0.036 seconds
[0m21:02:40.222615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '05a3dfef-a642-4889-b804-4a14f966960a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000113747E5CD0>]}
[0m21:02:40.222615 [debug] [MainThread]: On master: ROLLBACK
[0m21:02:40.222615 [debug] [MainThread]: On master: COMMIT
[0m21:02:40.222615 [debug] [MainThread]: Using postgres connection "master"
[0m21:02:40.222615 [debug] [MainThread]: On master: COMMIT
[0m21:02:40.222615 [debug] [MainThread]: SQL status: COMMIT in 0.002 seconds
[0m21:02:40.222615 [debug] [MainThread]: On master: Close
[0m21:02:40.233133 [debug] [Thread-1 (]: Began running node model.medical_warehouse.stg_telegram_messages
[0m21:02:40.233133 [info ] [Thread-1 (]: 1 of 2 START sql view model analytics_staging.stg_telegram_messages ............ [RUN]
[0m21:02:40.236215 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.medical_warehouse.stg_telegram_messages'
[0m21:02:40.236215 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.stg_telegram_messages
[0m21:02:40.243681 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.stg_telegram_messages"
[0m21:02:40.245756 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.stg_telegram_messages
[0m21:02:40.275202 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.stg_telegram_messages"
[0m21:02:40.275202 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:02:40.275202 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */

  create view "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_tmp"
    
    
  as (
    with source as (

    select *
    from "medical_warehouse"."raw"."telegram_messages"

),

cleaned as (

    select
        message_id,
        channel_name,
        message_text,
        message_date::timestamp as message_date,
        views::int as view_count,
        forwards::int as forward_count,
        has_media,
        length(message_text) as message_length
    from source
    where message_text is not null

)

select * from cleaned
  );
[0m21:02:40.275202 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:02:40.303007 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "raw.telegram_messages" does not exist
LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                  ^

[0m21:02:40.304042 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: ROLLBACK
[0m21:02:40.305003 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: Close
[0m21:02:40.311389 [debug] [Thread-1 (]: Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m21:02:40.313386 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05a3dfef-a642-4889-b804-4a14f966960a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011372DD3F50>]}
[0m21:02:40.314385 [error] [Thread-1 (]: 1 of 2 ERROR creating sql view model analytics_staging.stg_telegram_messages ... [[31mERROR[0m in 0.08s]
[0m21:02:40.315353 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.stg_telegram_messages
[0m21:02:40.316481 [debug] [Thread-4 (]: Marking all children of 'model.medical_warehouse.stg_telegram_messages' to be skipped because of status 'error'.  Reason: Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql.
[0m21:02:40.317517 [debug] [Thread-1 (]: Began running node model.medical_warehouse.fct_messages
[0m21:02:40.318482 [info ] [Thread-1 (]: 2 of 2 SKIP relation analytics_marts.fct_messages .............................. [[33mSKIP[0m]
[0m21:02:40.318482 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.fct_messages
[0m21:02:40.320481 [debug] [MainThread]: On master: COMMIT
[0m21:02:40.320481 [debug] [MainThread]: Using postgres connection "master"
[0m21:02:40.321518 [debug] [MainThread]: On master: COMMIT
[0m21:02:40.321518 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:02:40.346035 [debug] [MainThread]: SQL status: COMMIT in 0.025 seconds
[0m21:02:40.346035 [debug] [MainThread]: On master: Close
[0m21:02:40.346035 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:02:40.346035 [debug] [MainThread]: Connection 'list_medical_warehouse' was properly closed.
[0m21:02:40.346035 [debug] [MainThread]: Connection 'list_medical_warehouse_analytics_marts' was properly closed.
[0m21:02:40.346035 [debug] [MainThread]: Connection 'model.medical_warehouse.stg_telegram_messages' was properly closed.
[0m21:02:40.346035 [info ] [MainThread]: 
[0m21:02:40.346035 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.45 seconds (0.45s).
[0m21:02:40.346035 [debug] [MainThread]: Command end result
[0m21:02:40.387472 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:02:40.387472 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:02:40.401441 [debug] [MainThread]: Wrote artifact RunExecutionResult to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\run_results.json
[0m21:02:40.402440 [info ] [MainThread]: 
[0m21:02:40.403443 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:02:40.404800 [info ] [MainThread]: 
[0m21:02:40.404800 [error] [MainThread]: [31mFailure in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)[0m
[0m21:02:40.404800 [error] [MainThread]:   Database Error in model stg_telegram_messages (models\staging\stg_telegram_messages.sql)
  relation "raw.telegram_messages" does not exist
  LINE 10:     from "medical_warehouse"."raw"."telegram_messages"
                    ^
  compiled code at target\run\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m21:02:40.408085 [info ] [MainThread]: 
[0m21:02:40.409789 [info ] [MainThread]:   compiled code at target\compiled\medical_warehouse\models\staging\stg_telegram_messages.sql
[0m21:02:40.409789 [info ] [MainThread]: 
[0m21:02:40.409789 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=1 NO-OP=0 TOTAL=2
[0m21:02:40.409789 [debug] [MainThread]: Command `dbt run` failed at 21:02:40.409789 after 1.45 seconds
[0m21:02:40.409789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001136C2D0D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001137474AF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001137474BE90>]}
[0m21:02:40.415109 [debug] [MainThread]: Flushing usage events
[0m21:02:42.559057 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:10:47.126938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB626C6B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB62718650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB627185D0>]}


============================== 21:10:47.126938 | a614b19a-7dae-4b10-87cf-32875ec53cc5 ==============================
[0m21:10:47.126938 [info ] [MainThread]: Running with dbt=1.11.2
[0m21:10:47.126938 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'indirect_selection': 'eager', 'invocation_command': 'dbt debug', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m21:10:47.158759 [info ] [MainThread]: dbt version: 1.11.2
[0m21:10:47.158759 [info ] [MainThread]: python version: 3.11.0
[0m21:10:47.158759 [info ] [MainThread]: python path: E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\.venv\Scripts\python.exe
[0m21:10:47.158759 [info ] [MainThread]: os info: Windows-10-10.0.26100-SP0
[0m21:10:47.232765 [info ] [MainThread]: Using profiles dir at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse
[0m21:10:47.233765 [info ] [MainThread]: Using profiles.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\profiles.yml
[0m21:10:47.234783 [info ] [MainThread]: Using dbt_project.yml file at E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\dbt_project.yml
[0m21:10:47.235728 [info ] [MainThread]: adapter type: postgres
[0m21:10:47.236729 [info ] [MainThread]: adapter version: 1.10.0
[0m21:10:47.373526 [info ] [MainThread]: Configuration:
[0m21:10:47.374640 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m21:10:47.374640 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m21:10:47.374640 [info ] [MainThread]: Required dependencies:
[0m21:10:47.376776 [debug] [MainThread]: Executing "git --help"
[0m21:10:47.428283 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m21:10:47.428283 [debug] [MainThread]: STDERR: "b''"
[0m21:10:47.428283 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m21:10:47.428283 [info ] [MainThread]: Connection:
[0m21:10:47.428283 [info ] [MainThread]:   host: localhost
[0m21:10:47.428283 [info ] [MainThread]:   port: 5432
[0m21:10:47.428283 [info ] [MainThread]:   user: postgres
[0m21:10:47.428283 [info ] [MainThread]:   database: medical_warehouse
[0m21:10:47.428283 [info ] [MainThread]:   schema: analytics
[0m21:10:47.428283 [info ] [MainThread]:   connect_timeout: 10
[0m21:10:47.428283 [info ] [MainThread]:   role: None
[0m21:10:47.428283 [info ] [MainThread]:   search_path: None
[0m21:10:47.428283 [info ] [MainThread]:   keepalives_idle: 0
[0m21:10:47.438651 [info ] [MainThread]:   sslmode: None
[0m21:10:47.438651 [info ] [MainThread]:   sslcert: None
[0m21:10:47.440758 [info ] [MainThread]:   sslkey: None
[0m21:10:47.441767 [info ] [MainThread]:   sslrootcert: None
[0m21:10:47.442766 [info ] [MainThread]:   application_name: dbt
[0m21:10:47.443771 [info ] [MainThread]:   retries: 1
[0m21:10:47.444771 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m21:10:47.809437 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m21:10:47.870675 [debug] [MainThread]: Using postgres connection "debug"
[0m21:10:47.870675 [debug] [MainThread]: On debug: select 1 as id
[0m21:10:47.870675 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:10:47.912448 [debug] [MainThread]: SQL status: SELECT 1 in 0.041 seconds
[0m21:10:47.917444 [debug] [MainThread]: On debug: Close
[0m21:10:47.917444 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m21:10:47.917444 [info ] [MainThread]: [32mAll checks passed![0m
[0m21:10:47.921250 [debug] [MainThread]: Command `dbt debug` succeeded at 21:10:47.921250 after 0.86 seconds
[0m21:10:47.922793 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m21:10:47.922793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB626B3D50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB5BCC0E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EB6384D390>]}
[0m21:10:47.922793 [debug] [MainThread]: Flushing usage events
[0m21:10:49.379676 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:14:17.021895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D35F6F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D3640310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D3664790>]}


============================== 21:14:17.021895 | d59d5626-db7f-40de-9736-485c5642871f ==============================
[0m21:14:17.021895 [info ] [MainThread]: Running with dbt=1.11.2
[0m21:14:17.031829 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False', 'debug': 'False', 'log_format': 'default', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'invocation_command': 'dbt run', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m21:14:17.227435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd59d5626-db7f-40de-9736-485c5642871f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D486B550>]}
[0m21:14:17.299381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd59d5626-db7f-40de-9736-485c5642871f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192CFE30190>]}
[0m21:14:17.301070 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m21:14:17.576052 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m21:14:17.723212 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:14:17.723212 [debug] [MainThread]: Partial parsing: updated file: medical_warehouse://models\staging\stg_telegram_messages.sql
[0m21:14:18.008780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd59d5626-db7f-40de-9736-485c5642871f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D48BAC10>]}
[0m21:14:18.140585 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:14:18.142606 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:14:18.171246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd59d5626-db7f-40de-9736-485c5642871f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D4CDF450>]}
[0m21:14:18.172886 [info ] [MainThread]: Found 4 models, 1 test, 1 source, 464 macros
[0m21:14:18.172886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd59d5626-db7f-40de-9736-485c5642871f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D4EFEC50>]}
[0m21:14:18.175502 [info ] [MainThread]: 
[0m21:14:18.175502 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:14:18.176509 [info ] [MainThread]: 
[0m21:14:18.177509 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:14:18.181514 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse'
[0m21:14:18.261742 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m21:14:18.261742 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:14:18.262748 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:14:18.299598 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.039 seconds
[0m21:14:18.303641 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m21:14:18.308112 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m21:14:18.308112 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:14:18.309110 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:18.335722 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.027 seconds
[0m21:14:18.336724 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m21:14:18.339588 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse_analytics_marts'
[0m21:14:18.345160 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_marts"
[0m21:14:18.346701 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_marts"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m21:14:18.347706 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:14:18.392355 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.054 seconds
[0m21:14:18.402780 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: ROLLBACK
[0m21:14:18.402780 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: Close
[0m21:14:18.405572 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_medical_warehouse_analytics_marts, now list_medical_warehouse_analytics_staging)
[0m21:14:18.408444 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_staging"
[0m21:14:18.409442 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_staging"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m21:14:18.409442 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:18.437109 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.027 seconds
[0m21:14:18.438143 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: ROLLBACK
[0m21:14:18.438839 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: Close
[0m21:14:18.444316 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:18.444316 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m21:14:18.444316 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:14:18.487126 [debug] [MainThread]: SQL status: SELECT 0 in 0.041 seconds
[0m21:14:18.488755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd59d5626-db7f-40de-9736-485c5642871f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D4DE6C10>]}
[0m21:14:18.488755 [debug] [MainThread]: On master: ROLLBACK
[0m21:14:18.488755 [debug] [MainThread]: On master: COMMIT
[0m21:14:18.488755 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:18.488755 [debug] [MainThread]: On master: COMMIT
[0m21:14:18.488755 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:14:18.488755 [debug] [MainThread]: On master: Close
[0m21:14:18.496145 [debug] [Thread-1 (]: Began running node model.medical_warehouse.stg_telegram_messages
[0m21:14:18.496145 [info ] [Thread-1 (]: 1 of 2 START sql view model analytics_staging.stg_telegram_messages ............ [RUN]
[0m21:14:18.496145 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.medical_warehouse.stg_telegram_messages'
[0m21:14:18.496145 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.stg_telegram_messages
[0m21:14:18.506259 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.stg_telegram_messages"
[0m21:14:18.506259 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.stg_telegram_messages
[0m21:14:18.539441 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.stg_telegram_messages"
[0m21:14:18.539441 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:14:18.539441 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */

  create view "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_tmp"
    
    
  as (
    select
    message_id,
    channel_name,
    message_text,
    message_date,
    length(message_text) as message_length,
    view_count,
    forward_count,
    has_media,
    image_path
from "medical_warehouse"."raw"."telegram_messages"
where message_text is not null
  );
[0m21:14:18.539441 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:14:18.591157 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.045 seconds
[0m21:14:18.597199 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:14:18.598197 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */
alter table "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_tmp" rename to "stg_telegram_messages"
[0m21:14:18.599702 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:14:18.609840 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: COMMIT
[0m21:14:18.609840 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:14:18.609840 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: COMMIT
[0m21:14:18.620408 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:14:18.622569 [debug] [Thread-1 (]: Applying DROP to: "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_backup"
[0m21:14:18.630808 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:14:18.630808 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */
drop view if exists "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_backup" cascade
[0m21:14:18.630808 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.003 seconds
[0m21:14:18.638444 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: Close
[0m21:14:18.640999 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd59d5626-db7f-40de-9736-485c5642871f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D51C0750>]}
[0m21:14:18.640999 [info ] [Thread-1 (]: 1 of 2 OK created sql view model analytics_staging.stg_telegram_messages ....... [[32mCREATE VIEW[0m in 0.14s]
[0m21:14:18.640999 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.stg_telegram_messages
[0m21:14:18.640999 [debug] [Thread-1 (]: Began running node model.medical_warehouse.fct_messages
[0m21:14:18.640999 [info ] [Thread-1 (]: 2 of 2 START sql table model analytics_marts.fct_messages ...................... [RUN]
[0m21:14:18.640999 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medical_warehouse.stg_telegram_messages, now model.medical_warehouse.fct_messages)
[0m21:14:18.640999 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.fct_messages
[0m21:14:18.651318 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.fct_messages"
[0m21:14:18.655601 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.fct_messages
[0m21:14:18.682241 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.fct_messages"
[0m21:14:18.682241 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.fct_messages"
[0m21:14:18.682241 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.fct_messages"} */

  
    

  create  table "medical_warehouse"."analytics_marts"."fct_messages__dbt_tmp"
  
  
    as
  
  (
    select
    m.message_id,
    c.channel_key,
    d.date_key,
    m.message_text,
    m.message_length,
    m.view_count,
    m.forward_count,
    m.has_image
from "medical_warehouse"."analytics_staging"."stg_telegram_messages" as m
left join "medical_warehouse"."analytics_marts"."dim_channels" as c
    on m.channel_name = c.channel_name
left join "medical_warehouse"."analytics_marts"."dim_dates" as d
    on m.message_date::date = d.full_date
  );
  
[0m21:14:18.682241 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:18.719695 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_marts.dim_channels" does not exist
LINE 22: left join "medical_warehouse"."analytics_marts"."dim_channel...
                   ^

[0m21:14:18.720594 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: ROLLBACK
[0m21:14:18.722592 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: Close
[0m21:14:18.727702 [debug] [Thread-1 (]: Database Error in model fct_messages (models\marts\fct_messages.sql)
  relation "analytics_marts.dim_channels" does not exist
  LINE 22: left join "medical_warehouse"."analytics_marts"."dim_channel...
                     ^
  compiled code at target\run\medical_warehouse\models\marts\fct_messages.sql
[0m21:14:18.728692 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd59d5626-db7f-40de-9736-485c5642871f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D51C0690>]}
[0m21:14:18.729675 [error] [Thread-1 (]: 2 of 2 ERROR creating sql table model analytics_marts.fct_messages ............. [[31mERROR[0m in 0.09s]
[0m21:14:18.730674 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.fct_messages
[0m21:14:18.730674 [debug] [Thread-4 (]: Marking all children of 'model.medical_warehouse.fct_messages' to be skipped because of status 'error'.  Reason: Database Error in model fct_messages (models\marts\fct_messages.sql)
  relation "analytics_marts.dim_channels" does not exist
  LINE 22: left join "medical_warehouse"."analytics_marts"."dim_channel...
                     ^
  compiled code at target\run\medical_warehouse\models\marts\fct_messages.sql.
[0m21:14:18.732678 [debug] [MainThread]: On master: COMMIT
[0m21:14:18.733676 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:18.733676 [debug] [MainThread]: On master: COMMIT
[0m21:14:18.734674 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:14:18.756231 [debug] [MainThread]: SQL status: COMMIT in 0.024 seconds
[0m21:14:18.756231 [debug] [MainThread]: On master: Close
[0m21:14:18.756231 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:14:18.760383 [debug] [MainThread]: Connection 'list_medical_warehouse' was properly closed.
[0m21:14:18.760383 [debug] [MainThread]: Connection 'list_medical_warehouse_analytics_staging' was properly closed.
[0m21:14:18.760383 [debug] [MainThread]: Connection 'model.medical_warehouse.fct_messages' was properly closed.
[0m21:14:18.760383 [info ] [MainThread]: 
[0m21:14:18.762389 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m21:14:18.762389 [debug] [MainThread]: Command end result
[0m21:14:18.788744 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:14:18.791799 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:14:18.797380 [debug] [MainThread]: Wrote artifact RunExecutionResult to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\run_results.json
[0m21:14:18.797380 [info ] [MainThread]: 
[0m21:14:18.797380 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:14:18.797380 [info ] [MainThread]: 
[0m21:14:18.797380 [error] [MainThread]: [31mFailure in model fct_messages (models\marts\fct_messages.sql)[0m
[0m21:14:18.797380 [error] [MainThread]:   Database Error in model fct_messages (models\marts\fct_messages.sql)
  relation "analytics_marts.dim_channels" does not exist
  LINE 22: left join "medical_warehouse"."analytics_marts"."dim_channel...
                     ^
  compiled code at target\run\medical_warehouse\models\marts\fct_messages.sql
[0m21:14:18.797380 [info ] [MainThread]: 
[0m21:14:18.797380 [info ] [MainThread]:   compiled code at target\compiled\medical_warehouse\models\marts\fct_messages.sql
[0m21:14:18.797380 [info ] [MainThread]: 
[0m21:14:18.797380 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m21:14:18.805308 [debug] [MainThread]: Command `dbt run` failed at 21:14:18.805308 after 1.84 seconds
[0m21:14:18.806319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D3605890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192D3666CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000192CC8D65D0>]}
[0m21:14:18.806319 [debug] [MainThread]: Flushing usage events
[0m21:14:25.704512 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:19:25.721497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018770C26A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018770C14850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018770C157D0>]}


============================== 21:19:25.726506 | d2797745-09f4-41fa-acfc-673c8a0225ef ==============================
[0m21:19:25.726506 [info ] [MainThread]: Running with dbt=1.11.2
[0m21:19:25.727508 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt run', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m21:19:25.985851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018771E35FD0>]}
[0m21:19:26.062597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001876D450AD0>]}
[0m21:19:26.064191 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m21:19:26.349198 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m21:19:26.536796 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:19:26.536796 [debug] [MainThread]: Partial parsing: updated file: medical_warehouse://models\marts\dim_dates.sql
[0m21:19:26.538487 [debug] [MainThread]: Partial parsing: updated file: medical_warehouse://models\marts\dim_channels.sql
[0m21:19:26.539040 [debug] [MainThread]: Partial parsing: updated file: medical_warehouse://models\marts\fct_messages.sql
[0m21:19:26.887238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018772426650>]}
[0m21:19:27.038963 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:19:27.038963 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:19:27.069364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000187725184D0>]}
[0m21:19:27.069364 [info ] [MainThread]: Found 1 test, 4 models, 1 source, 464 macros
[0m21:19:27.076001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018772426A90>]}
[0m21:19:27.076001 [info ] [MainThread]: 
[0m21:19:27.076001 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:19:27.079094 [info ] [MainThread]: 
[0m21:19:27.079664 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:19:27.086264 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse'
[0m21:19:27.174419 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m21:19:27.174419 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:19:27.174419 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:27.200693 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.032 seconds
[0m21:19:27.209217 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m21:19:27.213582 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse"
[0m21:19:27.214197 [debug] [ThreadPool]: On list_medical_warehouse: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:19:27.214197 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:27.243352 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.029 seconds
[0m21:19:27.243352 [debug] [ThreadPool]: On list_medical_warehouse: Close
[0m21:19:27.247650 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse_analytics_staging'
[0m21:19:27.253575 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_staging"
[0m21:19:27.253575 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_staging"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m21:19:27.253575 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:27.289392 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.039 seconds
[0m21:19:27.295117 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: ROLLBACK
[0m21:19:27.297227 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: Close
[0m21:19:27.297599 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_medical_warehouse_analytics_staging, now list_medical_warehouse_analytics_marts)
[0m21:19:27.299108 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_marts"
[0m21:19:27.299108 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_marts"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m21:19:27.299108 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:27.325774 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.025 seconds
[0m21:19:27.330009 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: ROLLBACK
[0m21:19:27.331063 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: Close
[0m21:19:27.336184 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:27.336184 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m21:19:27.339227 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:19:27.379349 [debug] [MainThread]: SQL status: SELECT 1 in 0.041 seconds
[0m21:19:27.381909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018772463A10>]}
[0m21:19:27.381909 [debug] [MainThread]: On master: ROLLBACK
[0m21:19:27.381909 [debug] [MainThread]: On master: COMMIT
[0m21:19:27.381909 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:27.381909 [debug] [MainThread]: On master: COMMIT
[0m21:19:27.381909 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:19:27.381909 [debug] [MainThread]: On master: Close
[0m21:19:27.388978 [debug] [Thread-1 (]: Began running node model.medical_warehouse.stg_telegram_messages
[0m21:19:27.388978 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics_staging.stg_telegram_messages ............ [RUN]
[0m21:19:27.388978 [debug] [Thread-1 (]: Acquiring new postgres connection 'model.medical_warehouse.stg_telegram_messages'
[0m21:19:27.388978 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.stg_telegram_messages
[0m21:19:27.399373 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.stg_telegram_messages"
[0m21:19:27.399373 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.stg_telegram_messages
[0m21:19:27.441188 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.stg_telegram_messages"
[0m21:19:27.441188 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:19:27.441188 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */

  create view "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_tmp"
    
    
  as (
    select
    message_id,
    channel_name,
    message_text,
    message_date,
    length(message_text) as message_length,
    view_count,
    forward_count,
    has_media,
    image_path
from "medical_warehouse"."raw"."telegram_messages"
where message_text is not null
  );
[0m21:19:27.441188 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:19:27.477380 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.031 seconds
[0m21:19:27.482686 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:19:27.482686 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */
alter table "medical_warehouse"."analytics_staging"."stg_telegram_messages" rename to "stg_telegram_messages__dbt_backup"
[0m21:19:27.482686 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:19:27.489418 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:19:27.489418 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */
alter table "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_tmp" rename to "stg_telegram_messages"
[0m21:19:27.489418 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:19:27.509200 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: COMMIT
[0m21:19:27.509200 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:19:27.512773 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: COMMIT
[0m21:19:27.519453 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m21:19:27.523719 [debug] [Thread-1 (]: Applying DROP to: "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_backup"
[0m21:19:27.530019 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.stg_telegram_messages"
[0m21:19:27.530019 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.stg_telegram_messages"} */
drop view if exists "medical_warehouse"."analytics_staging"."stg_telegram_messages__dbt_backup" cascade
[0m21:19:27.539113 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.007 seconds
[0m21:19:27.539113 [debug] [Thread-1 (]: On model.medical_warehouse.stg_telegram_messages: Close
[0m21:19:27.545898 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018772353F50>]}
[0m21:19:27.545898 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics_staging.stg_telegram_messages ....... [[32mCREATE VIEW[0m in 0.16s]
[0m21:19:27.549113 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.stg_telegram_messages
[0m21:19:27.549113 [debug] [Thread-1 (]: Began running node model.medical_warehouse.dim_channels
[0m21:19:27.549113 [info ] [Thread-1 (]: 2 of 4 START sql table model analytics_marts.dim_channels ...................... [RUN]
[0m21:19:27.549113 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medical_warehouse.stg_telegram_messages, now model.medical_warehouse.dim_channels)
[0m21:19:27.549113 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.dim_channels
[0m21:19:27.554839 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.dim_channels"
[0m21:19:27.554839 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.dim_channels
[0m21:19:27.581454 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.dim_channels"
[0m21:19:27.585787 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.dim_channels"
[0m21:19:27.585787 [debug] [Thread-1 (]: On model.medical_warehouse.dim_channels: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.dim_channels"} */

  
    

  create  table "medical_warehouse"."analytics_marts"."dim_channels__dbt_tmp"
  
  
    as
  
  (
    

select
    row_number() over () as channel_key,
    channel_name,
    case
        when lower(channel_name) like '%pharma%' then 'Pharmaceutical'
        when lower(channel_name) like '%cosmetic%' then 'Cosmetics'
        else 'Medical'
    end as channel_type,
    min(message_date) as first_post_date,
    max(message_date) as last_post_date,
    count(*) as total_posts,
    avg(view_count) as avg_views
from "medical_warehouse"."analytics_staging"."stg_telegram_messages"
group by channel_name
  );
  
[0m21:19:27.585787 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:27.618944 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.032 seconds
[0m21:19:27.627003 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.dim_channels"
[0m21:19:27.627003 [debug] [Thread-1 (]: On model.medical_warehouse.dim_channels: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.dim_channels"} */
alter table "medical_warehouse"."analytics_marts"."dim_channels__dbt_tmp" rename to "dim_channels"
[0m21:19:27.629017 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:19:27.631981 [debug] [Thread-1 (]: On model.medical_warehouse.dim_channels: COMMIT
[0m21:19:27.632981 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.dim_channels"
[0m21:19:27.632981 [debug] [Thread-1 (]: On model.medical_warehouse.dim_channels: COMMIT
[0m21:19:27.635796 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:19:27.638378 [debug] [Thread-1 (]: Applying DROP to: "medical_warehouse"."analytics_marts"."dim_channels__dbt_backup"
[0m21:19:27.641709 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.dim_channels"
[0m21:19:27.642707 [debug] [Thread-1 (]: On model.medical_warehouse.dim_channels: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.dim_channels"} */
drop table if exists "medical_warehouse"."analytics_marts"."dim_channels__dbt_backup" cascade
[0m21:19:27.643671 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:19:27.646356 [debug] [Thread-1 (]: On model.medical_warehouse.dim_channels: Close
[0m21:19:27.646356 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000187728A94D0>]}
[0m21:19:27.649386 [info ] [Thread-1 (]: 2 of 4 OK created sql table model analytics_marts.dim_channels ................. [[32mSELECT 0[0m in 0.10s]
[0m21:19:27.650393 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.dim_channels
[0m21:19:27.651394 [debug] [Thread-1 (]: Began running node model.medical_warehouse.dim_dates
[0m21:19:27.651394 [info ] [Thread-1 (]: 3 of 4 START sql table model analytics_marts.dim_dates ......................... [RUN]
[0m21:19:27.652607 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medical_warehouse.dim_channels, now model.medical_warehouse.dim_dates)
[0m21:19:27.653612 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.dim_dates
[0m21:19:27.656612 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.dim_dates"
[0m21:19:27.657612 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.dim_dates
[0m21:19:27.662796 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.dim_dates"
[0m21:19:27.664729 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.dim_dates"
[0m21:19:27.665516 [debug] [Thread-1 (]: On model.medical_warehouse.dim_dates: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.dim_dates"} */

  
    

  create  table "medical_warehouse"."analytics_marts"."dim_dates__dbt_tmp"
  
  
    as
  
  (
    

select distinct
    cast(message_date as date) as full_date,
    extract(year from message_date)::int as year,
    extract(month from message_date)::int as month,
    extract(day from message_date)::int as day,
    extract(week from message_date)::int as week_of_year,
    extract(dow from message_date)::int as day_of_week,
    to_char(message_date, 'Day') as day_name,
    to_char(message_date, 'Month') as month_name,
    case when extract(dow from message_date) in (0,6) then true else false end as is_weekend
from "medical_warehouse"."analytics_staging"."stg_telegram_messages"
  );
  
[0m21:19:27.666608 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:27.698954 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.033 seconds
[0m21:19:27.703133 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.dim_dates"
[0m21:19:27.703133 [debug] [Thread-1 (]: On model.medical_warehouse.dim_dates: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.dim_dates"} */
alter table "medical_warehouse"."analytics_marts"."dim_dates__dbt_tmp" rename to "dim_dates"
[0m21:19:27.703133 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:19:27.703133 [debug] [Thread-1 (]: On model.medical_warehouse.dim_dates: COMMIT
[0m21:19:27.703133 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.dim_dates"
[0m21:19:27.703133 [debug] [Thread-1 (]: On model.medical_warehouse.dim_dates: COMMIT
[0m21:19:27.711147 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:19:27.716299 [debug] [Thread-1 (]: Applying DROP to: "medical_warehouse"."analytics_marts"."dim_dates__dbt_backup"
[0m21:19:27.718340 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.dim_dates"
[0m21:19:27.718340 [debug] [Thread-1 (]: On model.medical_warehouse.dim_dates: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.dim_dates"} */
drop table if exists "medical_warehouse"."analytics_marts"."dim_dates__dbt_backup" cascade
[0m21:19:27.720593 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:19:27.722138 [debug] [Thread-1 (]: On model.medical_warehouse.dim_dates: Close
[0m21:19:27.723177 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000187728D8C50>]}
[0m21:19:27.725147 [info ] [Thread-1 (]: 3 of 4 OK created sql table model analytics_marts.dim_dates .................... [[32mSELECT 0[0m in 0.07s]
[0m21:19:27.726141 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.dim_dates
[0m21:19:27.727828 [debug] [Thread-1 (]: Began running node model.medical_warehouse.fct_messages
[0m21:19:27.727828 [info ] [Thread-1 (]: 4 of 4 START sql table model analytics_marts.fct_messages ...................... [RUN]
[0m21:19:27.729371 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.medical_warehouse.dim_dates, now model.medical_warehouse.fct_messages)
[0m21:19:27.730761 [debug] [Thread-1 (]: Began compiling node model.medical_warehouse.fct_messages
[0m21:19:27.736438 [debug] [Thread-1 (]: Writing injected SQL for node "model.medical_warehouse.fct_messages"
[0m21:19:27.737467 [debug] [Thread-1 (]: Began executing node model.medical_warehouse.fct_messages
[0m21:19:27.743613 [debug] [Thread-1 (]: Writing runtime sql for node "model.medical_warehouse.fct_messages"
[0m21:19:27.744649 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.fct_messages"
[0m21:19:27.746571 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.fct_messages"} */

  
    

  create  table "medical_warehouse"."analytics_marts"."fct_messages__dbt_tmp"
  
  
    as
  
  (
    

select
    s.message_id,
    dc.channel_key,
    dd.full_date as date_key,
    s.message_text,
    s.message_length,
    s.view_count,
    s.forward_count,
    s.has_media as has_image
from "medical_warehouse"."analytics_staging"."stg_telegram_messages" s
left join "medical_warehouse"."analytics_marts"."dim_channels" dc
    on s.channel_name = dc.channel_name
left join "medical_warehouse"."analytics_marts"."dim_dates" dd
    on cast(s.message_date as date) = dd.full_date
  );
  
[0m21:19:27.747053 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:27.783565 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.040 seconds
[0m21:19:27.789080 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.fct_messages"
[0m21:19:27.789080 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.fct_messages"} */
alter table "medical_warehouse"."analytics_marts"."fct_messages__dbt_tmp" rename to "fct_messages"
[0m21:19:27.793547 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:19:27.793547 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: COMMIT
[0m21:19:27.793547 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.fct_messages"
[0m21:19:27.797105 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: COMMIT
[0m21:19:27.800095 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m21:19:27.803676 [debug] [Thread-1 (]: Applying DROP to: "medical_warehouse"."analytics_marts"."fct_messages__dbt_backup"
[0m21:19:27.804721 [debug] [Thread-1 (]: Using postgres connection "model.medical_warehouse.fct_messages"
[0m21:19:27.805684 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "model.medical_warehouse.fct_messages"} */
drop table if exists "medical_warehouse"."analytics_marts"."fct_messages__dbt_backup" cascade
[0m21:19:27.806686 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:19:27.809271 [debug] [Thread-1 (]: On model.medical_warehouse.fct_messages: Close
[0m21:19:27.810280 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd2797745-09f4-41fa-acfc-673c8a0225ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000187728D9010>]}
[0m21:19:27.811283 [info ] [Thread-1 (]: 4 of 4 OK created sql table model analytics_marts.fct_messages ................. [[32mSELECT 0[0m in 0.08s]
[0m21:19:27.812281 [debug] [Thread-1 (]: Finished running node model.medical_warehouse.fct_messages
[0m21:19:27.814946 [debug] [MainThread]: On master: COMMIT
[0m21:19:27.815944 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:27.815944 [debug] [MainThread]: On master: COMMIT
[0m21:19:27.817298 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:19:27.857473 [debug] [MainThread]: SQL status: COMMIT in 0.040 seconds
[0m21:19:27.857473 [debug] [MainThread]: On master: Close
[0m21:19:27.858988 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:27.858988 [debug] [MainThread]: Connection 'list_medical_warehouse' was properly closed.
[0m21:19:27.858988 [debug] [MainThread]: Connection 'list_medical_warehouse_analytics_marts' was properly closed.
[0m21:19:27.858988 [debug] [MainThread]: Connection 'model.medical_warehouse.fct_messages' was properly closed.
[0m21:19:27.858988 [info ] [MainThread]: 
[0m21:19:27.858988 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 0.78 seconds (0.78s).
[0m21:19:27.863694 [debug] [MainThread]: Command end result
[0m21:19:27.890143 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:19:27.890143 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:19:27.901418 [debug] [MainThread]: Wrote artifact RunExecutionResult to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\run_results.json
[0m21:19:27.902382 [info ] [MainThread]: 
[0m21:19:27.903382 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:19:27.904387 [info ] [MainThread]: 
[0m21:19:27.904387 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m21:19:27.904387 [debug] [MainThread]: Command `dbt run` succeeded at 21:19:27.904387 after 2.27 seconds
[0m21:19:27.907135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001876FD5C950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000187708C8590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001876A190E50>]}
[0m21:19:27.907135 [debug] [MainThread]: Flushing usage events
[0m21:19:30.572108 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:23:17.778108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026430E66150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026430D2D0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026430D2D210>]}


============================== 21:23:17.785033 | c4255b7b-f8cd-440b-bc0c-bf56dc7bd784 ==============================
[0m21:23:17.785033 [info ] [MainThread]: Running with dbt=1.11.2
[0m21:23:17.785033 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'no_print': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'printer_width': '80', 'write_json': 'True', 'empty': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'profiles_dir': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'invocation_command': 'dbt test', 'use_experimental_parser': 'False', 'log_path': 'E:\\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\\medical_warehouse\\logs'}
[0m21:23:18.002089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c4255b7b-f8cd-440b-bc0c-bf56dc7bd784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026431FEDA50>]}
[0m21:23:18.075077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c4255b7b-f8cd-440b-bc0c-bf56dc7bd784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002642D6308D0>]}
[0m21:23:18.078394 [info ] [MainThread]: Registered adapter: postgres=1.10.0
[0m21:23:18.369294 [debug] [MainThread]: checksum: 3d40d8bbe1bef07db1c24822f2dbfff8bc07f2a48ed4fe2658a40653aec0b54b, vars: {}, profile: , target: , version: 1.11.2
[0m21:23:18.529713 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:23:18.529713 [debug] [MainThread]: Nothing changed, skipping partial parsing.
[0m21:23:18.533636 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:23:18.580805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c4255b7b-f8cd-440b-bc0c-bf56dc7bd784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026430E979D0>]}
[0m21:23:18.688321 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:23:18.692071 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:23:18.738032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4255b7b-f8cd-440b-bc0c-bf56dc7bd784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002643267FD90>]}
[0m21:23:18.738032 [info ] [MainThread]: Found 1 test, 4 models, 1 source, 464 macros
[0m21:23:18.741968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c4255b7b-f8cd-440b-bc0c-bf56dc7bd784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002643229C190>]}
[0m21:23:18.744975 [info ] [MainThread]: 
[0m21:23:18.745975 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:23:18.745975 [info ] [MainThread]: 
[0m21:23:18.747945 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:23:18.753116 [debug] [ThreadPool]: Acquiring new postgres connection 'list_medical_warehouse_analytics_marts'
[0m21:23:18.888300 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_marts"
[0m21:23:18.889306 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_marts"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m21:23:18.889306 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:23:18.925793 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.036 seconds
[0m21:23:18.926792 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: ROLLBACK
[0m21:23:18.928311 [debug] [ThreadPool]: On list_medical_warehouse_analytics_marts: Close
[0m21:23:18.930320 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_medical_warehouse_analytics_marts, now list_medical_warehouse_analytics_staging)
[0m21:23:18.935887 [debug] [ThreadPool]: Using postgres connection "list_medical_warehouse_analytics_staging"
[0m21:23:18.935887 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "list_medical_warehouse_analytics_staging"} */
select
      'medical_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'medical_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m21:23:18.936888 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:23:18.958655 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.022 seconds
[0m21:23:18.960641 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: ROLLBACK
[0m21:23:18.962029 [debug] [ThreadPool]: On list_medical_warehouse_analytics_staging: Close
[0m21:23:18.967771 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:18.968398 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "connection_name": "master"} */
select distinct
        dependent_namespace.nspname as dependent_schema,
        dependent_class.relname as dependent_name,
        referenced_namespace.nspname as referenced_schema,
        referenced_class.relname as referenced_name

    -- Query for views: views are entries in pg_class with an entry in pg_rewrite, but we avoid
    -- a seq scan on pg_rewrite by leveraging the fact there is an "internal" row in pg_depend for
    -- the view...
    from pg_class as dependent_class
    join pg_namespace as dependent_namespace on dependent_namespace.oid = dependent_class.relnamespace
    join pg_depend as dependent_depend on dependent_depend.refobjid = dependent_class.oid
        and dependent_depend.classid = 'pg_rewrite'::regclass
        and dependent_depend.refclassid = 'pg_class'::regclass
        and dependent_depend.deptype = 'i'

    -- ... and via pg_depend (that has a row per column, hence the need for "distinct" above, and
    -- making sure to exclude the internal row to avoid a view appearing to depend on itself)...
    join pg_depend as joining_depend on joining_depend.objid = dependent_depend.objid
        and joining_depend.classid = 'pg_rewrite'::regclass
        and joining_depend.refclassid = 'pg_class'::regclass
        and joining_depend.refobjid != dependent_depend.refobjid

    -- ... we can find the tables they query from in pg_class, but excluding system tables. Note we
    -- don't need need to exclude _dependent_ system tables, because they only query from other
    -- system tables, and so are automatically excluded by excluding _referenced_ system tables
    join pg_class as referenced_class on referenced_class.oid = joining_depend.refobjid
    join pg_namespace as referenced_namespace on referenced_namespace.oid = referenced_class.relnamespace
        and referenced_namespace.nspname != 'information_schema'
        and referenced_namespace.nspname not like 'pg\_%'

    order by
        dependent_schema, dependent_name, referenced_schema, referenced_name;
[0m21:23:18.968398 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:23:18.999815 [debug] [MainThread]: SQL status: SELECT 1 in 0.032 seconds
[0m21:23:19.002600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c4255b7b-f8cd-440b-bc0c-bf56dc7bd784', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000264324FCD10>]}
[0m21:23:19.002600 [debug] [MainThread]: On master: ROLLBACK
[0m21:23:19.003598 [debug] [MainThread]: On master: COMMIT
[0m21:23:19.005103 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:19.005103 [debug] [MainThread]: On master: COMMIT
[0m21:23:19.007596 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m21:23:19.008120 [debug] [MainThread]: On master: Close
[0m21:23:19.012950 [debug] [Thread-1 (]: Began running node test.medical_warehouse.assert_no_future_messages
[0m21:23:19.013962 [info ] [Thread-1 (]: 1 of 1 START test assert_no_future_messages .................................... [RUN]
[0m21:23:19.015469 [debug] [Thread-1 (]: Acquiring new postgres connection 'test.medical_warehouse.assert_no_future_messages'
[0m21:23:19.015797 [debug] [Thread-1 (]: Began compiling node test.medical_warehouse.assert_no_future_messages
[0m21:23:19.024923 [debug] [Thread-1 (]: Writing injected SQL for node "test.medical_warehouse.assert_no_future_messages"
[0m21:23:19.026972 [debug] [Thread-1 (]: Began executing node test.medical_warehouse.assert_no_future_messages
[0m21:23:19.049771 [debug] [Thread-1 (]: Writing runtime sql for node "test.medical_warehouse.assert_no_future_messages"
[0m21:23:19.052614 [debug] [Thread-1 (]: Using postgres connection "test.medical_warehouse.assert_no_future_messages"
[0m21:23:19.052614 [debug] [Thread-1 (]: On test.medical_warehouse.assert_no_future_messages: /* {"app": "dbt", "dbt_version": "1.11.2", "profile_name": "medical_warehouse", "target_name": "dev", "node_id": "test.medical_warehouse.assert_no_future_messages"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  select *
from "medical_warehouse"."analytics_staging"."stg_telegram_messages"
where message_date > current_timestamp
  
  
      
    ) dbt_internal_test
[0m21:23:19.052614 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:23:19.089819 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.035 seconds
[0m21:23:19.093824 [debug] [Thread-1 (]: On test.medical_warehouse.assert_no_future_messages: ROLLBACK
[0m21:23:19.095824 [debug] [Thread-1 (]: On test.medical_warehouse.assert_no_future_messages: Close
[0m21:23:19.096854 [info ] [Thread-1 (]: 1 of 1 PASS assert_no_future_messages .......................................... [[32mPASS[0m in 0.08s]
[0m21:23:19.098361 [debug] [Thread-1 (]: Finished running node test.medical_warehouse.assert_no_future_messages
[0m21:23:19.100394 [debug] [MainThread]: On master: COMMIT
[0m21:23:19.100394 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:19.100394 [debug] [MainThread]: On master: COMMIT
[0m21:23:19.101906 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:23:19.128064 [debug] [MainThread]: SQL status: COMMIT in 0.027 seconds
[0m21:23:19.129578 [debug] [MainThread]: On master: Close
[0m21:23:19.129578 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:23:19.129578 [debug] [MainThread]: Connection 'list_medical_warehouse_analytics_staging' was properly closed.
[0m21:23:19.131595 [debug] [MainThread]: Connection 'test.medical_warehouse.assert_no_future_messages' was properly closed.
[0m21:23:19.131595 [info ] [MainThread]: 
[0m21:23:19.131595 [info ] [MainThread]: Finished running 1 test in 0 hours 0 minutes and 0.38 seconds (0.38s).
[0m21:23:19.131595 [debug] [MainThread]: Command end result
[0m21:23:19.164765 [debug] [MainThread]: Wrote artifact WritableManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\manifest.json
[0m21:23:19.166768 [debug] [MainThread]: Wrote artifact SemanticManifest to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\semantic_manifest.json
[0m21:23:19.176620 [debug] [MainThread]: Wrote artifact RunExecutionResult to E:\Shipping-a-Data-Product-From-Raw-Telegram-Data-to-an-Analytical-API-week_8\medical_warehouse\target\run_results.json
[0m21:23:19.176620 [info ] [MainThread]: 
[0m21:23:19.178131 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:23:19.179138 [info ] [MainThread]: 
[0m21:23:19.180145 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m21:23:19.181645 [debug] [MainThread]: Command `dbt test` succeeded at 21:23:19.181645 after 1.47 seconds
[0m21:23:19.181645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002642A400E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000264329F9F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002642A156590>]}
[0m21:23:19.182654 [debug] [MainThread]: Flushing usage events
[0m21:23:20.598373 [debug] [MainThread]: An error was encountered while trying to flush usage events
